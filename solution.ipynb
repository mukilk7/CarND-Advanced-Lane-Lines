{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Helper Functions\n",
    "\n",
    "def plotImageFiles(filenames):\n",
    "    for f in filenames:\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(3,6)\n",
    "        img = mpimg.imread(f)\n",
    "        plt.title(f)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        \n",
    "def plotImage(img, title=None, cmap=None):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(4,8)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    if cmap is None:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    \n",
    "def plotMultipleImages(images, labels=None, ptitle=None, cmap=None):\n",
    "    \"\"\" This function will plot the images specified in a\n",
    "    single plot.\n",
    "    \"\"\"\n",
    "    numImages = len(images)\n",
    "    #fig = plt.figure(figsize=(3, 6*numImages))\n",
    "    fig = plt.figure()\n",
    "    if ptitle is not None:\n",
    "        fig.suptitle(ptitle, fontsize=\"x-large\")\n",
    "    ii = 1\n",
    "    for img in images:\n",
    "        ax = fig.add_subplot(1, numImages, ii)\n",
    "        if labels is not None:\n",
    "            ax.set_title(labels[ii-1], fontsize=\"xx-small\")\n",
    "        ax.set_aspect(15)\n",
    "        plt.axis('off')\n",
    "        if cmap is not None:\n",
    "            ax.imshow(img.squeeze(), cmap=cmap)\n",
    "        else:\n",
    "            ax.imshow(img.squeeze())\n",
    "        ii += 1\n",
    "        \n",
    "def plotImageAndPolygon(img, polygonPts):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    pgn = plt.Polygon(polygonPts, color='r', alpha=0.25, lw=2)\n",
    "    ax.imshow(img)\n",
    "    ax.add_patch(pgn)\n",
    "    \n",
    "def plotImageAndMultiplePolygons(img, multPolyPts1, multPolyPts2, cmap=None):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    if cmap is None:\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        ax.imshow(img, cmap=cmap)\n",
    "    for p in range(0, len(multPolyPts1)):\n",
    "        pgn1 = plt.Polygon(multPolyPts1[p], color='r', alpha=0.25, lw=1)\n",
    "        pgn2 = plt.Polygon(multPolyPts2[p], color='b', alpha=0.25, lw=1)\n",
    "        ax.add_patch(pgn1)\n",
    "        ax.add_patch(pgn2)\n",
    "        \n",
    "def plot3SideBySide(oimg, timg, hist):\n",
    "    fig = plt.figure(figsize=(12,3))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(oimg)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(timg, cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.plot(hist)\n",
    "    \n",
    "def plotLaneFit(timg, llfit, rlfit):\n",
    "    plt.figure()\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, timg.shape[0]-1, timg.shape[0] )\n",
    "    left_fitx = llfit[0]*ploty**2 + llfit[1]*ploty + llfit[2]\n",
    "    right_fitx = rlfit[0]*ploty**2 + rlfit[1]*ploty + rlfit[2]\n",
    "    plt.imshow(timg, cmap=\"gray\")\n",
    "    plt.plot(left_fitx, ploty, color='r', lw=3)\n",
    "    plt.plot(right_fitx, ploty, color='b', lw=3)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    \n",
    "print(\"*** Helper Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Camera Calibration\n",
    "\n",
    "def calibrateCamera():\n",
    "    imfiles = glob.glob('camera_cal/calibration*.jpg')\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "    #3d real world points\n",
    "    objPoints = []\n",
    "    #2d camera image points\n",
    "    imgPoints = []\n",
    "    #Corners returned by findChessboardCorners contains corners \n",
    "    #going left to right and then down. So we have to generate the\n",
    "    #idealized objpoint to go in the same direction. We also assume\n",
    "    #that the z-axis is 0 in the objpoint i.e., the image is placed\n",
    "    #on a 2d plane\n",
    "    objpoint = np.zeros((nx*ny, 3), np.float32)\n",
    "    objpoint[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "    for imfile in imfiles:\n",
    "        img = mpimg.imread(imfile)\n",
    "        #print(imfile)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        if ret:\n",
    "            imgPoints.append(corners)\n",
    "            objPoints.append(objpoint)\n",
    "    #ret, mtx, dist, rvecs, tvecs\n",
    "    return cv2.calibrateCamera(objPoints, imgPoints, (gray.shape[1], gray.shape[0]), None, None)\n",
    " \n",
    "def plotUndistortedImages():\n",
    "    imfiles = glob.glob('camera_cal/calibration*.jpg')\n",
    "    ret, mtx, dist, rvecs, tvecs = calibrateCamera()\n",
    "    for imfile in imfiles:\n",
    "        img = mpimg.imread(imfile)\n",
    "        dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        fig = plt.figure()\n",
    "        fig.add_subplot(1, 2, 1)\n",
    "        #plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        fig.add_subplot(1, 2, 2)\n",
    "        plt.imshow(dst)\n",
    "\n",
    "#plotUndistortedImages()\n",
    "print(\"*** Camera Calibration Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient and Color Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getUndistortedImage(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "def genericSobelThresholding(img, mfunc, ksize=3, thresh=(0,255)):\n",
    "    # Grayscale transformation if the image has 3 channels\n",
    "    # Otherwise assume it has already been transformed\n",
    "    if img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply cv2.Sobel()\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    scaled_sobel = mfunc(sobelx, sobely)\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel < thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def gradientAbsoluteThresholding(img, orient='x', ksize=3, thresh=(0,255)):\n",
    "    def gradAbsSobel(sobelx, sobely):\n",
    "        #Calculate scaled value of gradient\n",
    "        if orient == 'x':\n",
    "            sobel = sobelx\n",
    "        else:\n",
    "            sobel = sobely\n",
    "        abs_sobel = np.absolute(sobel)\n",
    "        scaled_sobel = np.uint8((abs_sobel * 255) / np.max(abs_sobel))\n",
    "        return scaled_sobel\n",
    "    return genericSobelThresholding(img, gradAbsSobel, ksize, thresh)\n",
    "\n",
    "def gradientMagnitudeThresholding(img, ksize=3, thresh=(0,255)):\n",
    "    def gradMagSobel(sobelx, sobely):\n",
    "        #Calculate scaled magnitude of gradient\n",
    "        gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "        scaled_gradmag = np.uint8((gradmag * 255) / np.max(gradmag))\n",
    "        return scaled_gradmag\n",
    "    return genericSobelThresholding(img, gradMagSobel, ksize, thresh)\n",
    "\n",
    "def gradientDirectionThresholding(img, ksize=3, thresh=(0,np.pi/2)):\n",
    "    def gradDirSobel(sobelx, sobely):\n",
    "        #Calculate direction of gradient\n",
    "        absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "        return absgraddir\n",
    "    return genericSobelThresholding(img, gradDirSobel, ksize, thresh)\n",
    "\n",
    "def colorThresholding(img, channel=0, colspace = cv2.COLOR_RGB2HLS, thresh=(0,255)):\n",
    "    img = cv2.cvtColor(img, colspace)\n",
    "    colchannel = img[:,:,channel]\n",
    "    binary_output = np.zeros_like(colchannel)\n",
    "    binary_output[(colchannel > thresh[0]) & (colchannel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "print(\"*** Gradient and Color Thresholding Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the perspective transformation matrix using the straight line test images\n",
    "\n",
    "def getPerspectiveTransformedImage(img, M):\n",
    "    img_shape = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_shape, flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "def getPerspectiveTransformationMatrix(inverse=False):\n",
    "    #Manually identified source points for Image 2\n",
    "    #bottom-left, bottom-right, top-right, top-left - (x, y)\n",
    "    ## Other values that also work\n",
    "    #srcpts2 = np.float32([(337, 633), (975, 633), (709, 463), (575, 463)])\n",
    "    #dstpts2 = np.float32([(300, 720), (900, 720), (900, 0), (300, 0)])\n",
    "    srcpts2 = np.float32([(337, 633), (975, 633), (709, 463), (575, 463)])\n",
    "    dstpts2 = np.float32([(200, 720), (1000, 720), (1000, 0), (200, 0)])\n",
    "    slfile2 = 'test_images/straight_lines2.jpg'\n",
    "    if not inverse:\n",
    "        M = cv2.getPerspectiveTransform(srcpts2, dstpts2)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(dstpts2, srcpts2)\n",
    "    return M\n",
    "\n",
    "def testPerspectiveTransformation(M):\n",
    "    #Manually identified source points for Image 1\n",
    "    #bottom-left, bottom-right, top-right, top-left - (x, y)\n",
    "    srcpts1 = np.float32([(331, 633), (973, 633), (702, 461), (581, 461)])\n",
    "    dstpts1 = np.float32([(200, 720), (1000, 720), (1000, 0), (200, 0)])\n",
    "    slfile1 = 'test_images/straight_lines1.jpg'\n",
    "    origImg1 = mpimg.imread(slfile1)\n",
    "    warpedImg1 = getPerspectiveTransformedImage(origImg1, M)\n",
    "    plotImageAndPolygon(origImg1, srcpts1)\n",
    "    plotImageAndPolygon(warpedImg1, dstpts1)\n",
    "    \n",
    "print(\"*** Perspective Transformation Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFittedLanePixels(img_shape, llfit, rlfit):\n",
    "    # Evenly spaced y-pixel values\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    #X values corresponding to the y-pixels\n",
    "    leftfitx = llfit[0] * ploty ** 2 + llfit[1] * ploty + llfit[2]\n",
    "    rightfitx = rlfit[0] * ploty ** 2 + rlfit[1] * ploty + rlfit[2]\n",
    "    return ploty, leftfitx, rightfitx\n",
    "\n",
    "def getRadiusOfCurvatureOfFitInPixels(img_shape, llfit, rlfit):\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0] )\n",
    "    y_eval = np.max(ploty)\n",
    "    llRadCurve = ((1 + (2 * llfit[0] * y_eval + llfit[1]) ** 2) ** 1.5) / np.absolute(2 * llfit[0])\n",
    "    rlRadCurve = ((1 + (2 * rlfit[0] * y_eval + rlfit[1]) ** 2) ** 1.5) / np.absolute(2 * rlfit[0])\n",
    "    return llRadCurve, rlRadCurve\n",
    "\n",
    "def getRadiusOfCurvatureOfFitInMeters(img_shape, llfit, rlfit):\n",
    "    # Assumed meters per pixel in our image each dimension\n",
    "    ym_per_pix = 30/720\n",
    "    xm_per_pix = 3.7/700\n",
    "    ploty, leftfitx, rightfitx = getFittedLanePixels(img_shape, llfit, rlfit)\n",
    "    y_eval = np.max(ploty)\n",
    "    # Fit new polynomials to x,y in world space after using above conversion factors\n",
    "    llFitMeters = np.polyfit(ploty * ym_per_pix, leftfitx * xm_per_pix, 2)\n",
    "    rlFitMeters = np.polyfit(ploty * ym_per_pix, rightfitx * xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    llRadCurve = ((1 + (2 * llFitMeters[0] * y_eval * ym_per_pix + llFitMeters[1]) ** 2) ** 1.5)\n",
    "    llRadCurve /= np.absolute(2 * llFitMeters[0])\n",
    "    rlRadCurve = ((1 + (2 * rlFitMeters[0] * y_eval * ym_per_pix + rlFitMeters[1]) ** 2) ** 1.5)\n",
    "    rlRadCurve /= np.absolute(2 * rlFitMeters[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    return llRadCurve, rlRadCurve\n",
    "\n",
    "def getVehicleDeviationFromLaneCenterInPixels(img_shape, llfit, rlfit):\n",
    "    ploty, leftfitx, rightfitx = getFittedLanePixels(img_shape, llfit, rlfit)\n",
    "    #Get a single pixel representing the left and right lanes\n",
    "    #at the bottom of the image. This is where y = img.shape[0].\n",
    "    maxy = np.argmax(ploty)\n",
    "    llpix = leftfitx[maxy]\n",
    "    rlpix = rightfitx[maxy]\n",
    "    lanecenter = (rlpix - llpix) // 2\n",
    "    camcenter = img_shape[1] // 2\n",
    "    deviationFromCenterInPixels = camcenter - lanecenter\n",
    "    return deviationFromCenterInPixels\n",
    "\n",
    "def getVehicleDeviationFromLaneCenterInMeters(img_shape, llfit, rlfit):\n",
    "    xm_per_pix = 3.7/700\n",
    "    deviationFromCenterInPixels = getVehicleDeviationFromLaneCenterInPixels(img_shape, llfit, rlfit)\n",
    "    return xm_per_pix * deviationFromCenterInPixels\n",
    "\n",
    "def slidingWindowLaneDetect(timg, nwindows=9, winextent=100, winshiftthresh=300, enableplot = False):\n",
    "    \"\"\" Detects lane lines using a sliding window that starts at the bottom of\n",
    "    the given image and recenters itself based on lane curvature. It returns a\n",
    "    tuple of polynomial fits for left lane and right lane respectively.\n",
    "    \"\"\"\n",
    "    hist = np.sum(timg[timg.shape[0]/3:, :], axis = 0)\n",
    "    midpt = hist.shape[0]//2\n",
    "    llxbase = np.argmax(hist[0:midpt])\n",
    "    rlxbase = np.argmax(hist[midpt:]) + midpt\n",
    "    nz = timg.nonzero()\n",
    "    nzx = np.array(nz[1])\n",
    "    nzy = np.array(nz[0])    \n",
    "    #Holds all the non-zero left lane pixels\n",
    "    ll_pixels = []\n",
    "    #Holds all the non-zero right lane pixels\n",
    "    rl_pixels = []\n",
    "    #Holds window corners for plotting\n",
    "    llPolyPts = []\n",
    "    rlPolyPts = []\n",
    "    for i in range(0, nwindows):\n",
    "        #Compute left lane sliding window corners' (x,y)\n",
    "        ll_win_x_left = llxbase - winextent\n",
    "        ll_win_x_right = llxbase + winextent\n",
    "        ll_win_y_high = timg.shape[0] - i * (timg.shape[0]//nwindows)\n",
    "        ll_win_y_low = ll_win_y_high - (timg.shape[0]//nwindows)       \n",
    "        if enableplot:\n",
    "            #bl, br, tr, tl\n",
    "            ll_rect = [(ll_win_x_left, ll_win_y_low), (ll_win_x_right, ll_win_y_low),\\\n",
    "                       (ll_win_x_right, ll_win_y_high), (ll_win_x_left, ll_win_y_high)]\n",
    "            llPolyPts.append(ll_rect)\n",
    "        #Compute right lane sliding window corners' (x,y)\n",
    "        rl_win_x_left = rlxbase - winextent\n",
    "        rl_win_x_right = rlxbase + winextent\n",
    "        rl_win_y_high = timg.shape[0] - i * (timg.shape[0]//nwindows)\n",
    "        rl_win_y_low = rl_win_y_high - (timg.shape[0]//nwindows)\n",
    "        if enableplot:\n",
    "            #bl, br, tr, tl\n",
    "            rl_rect = [(rl_win_x_left, rl_win_y_low), (rl_win_x_right, rl_win_y_low),\\\n",
    "                       (rl_win_x_right, rl_win_y_high), (rl_win_x_left, rl_win_y_high)]\n",
    "            rlPolyPts.append(rl_rect)\n",
    "        #Compute pixels that are non-zero within sliding window\n",
    "        ll_win_pixels = ((nzx >= ll_win_x_left) & (nzx < ll_win_x_right)\\\n",
    "                                 & (nzy >= ll_win_y_low) & (nzy < ll_win_y_high)).nonzero()[0]\n",
    "        ll_pixels.append(ll_win_pixels)\n",
    "        \n",
    "        rl_win_pixels = ((nzx >= rl_win_x_left) & (nzx < rl_win_x_right)\\\n",
    "                                 & (nzy >= rl_win_y_low) & (nzy < rl_win_y_high)).nonzero()[0]\n",
    "        rl_pixels.append(rl_win_pixels)\n",
    "        \n",
    "        #Shift lane bases if we have a lot of non-zero pixels in this sliding window\n",
    "        if len(ll_win_pixels) > winshiftthresh:\n",
    "            llxbase = int(np.mean(nzx[ll_win_pixels]))\n",
    "        if len(rl_win_pixels) > winshiftthresh:\n",
    "            rlxbase = int(np.mean(nzx[rl_win_pixels]))\n",
    "    \n",
    "    if enableplot:\n",
    "        plotImageAndMultiplePolygons(timg, llPolyPts, rlPolyPts, cmap=\"gray\")\n",
    "    \n",
    "    ll_pixels = np.concatenate(ll_pixels)\n",
    "    rl_pixels = np.concatenate(rl_pixels)\n",
    "    llx = nzx[ll_pixels]\n",
    "    lly = nzy[ll_pixels]\n",
    "    rlx = nzx[rl_pixels]\n",
    "    rly = nzy[rl_pixels]\n",
    "    \n",
    "    llfit = np.polyfit(lly, llx, 2)\n",
    "    rlfit = np.polyfit(rly, rlx, 2)\n",
    "    \n",
    "    return llfit, rlfit\n",
    "\n",
    "\n",
    "def targetedLaneDetect(warpedImage, prevllfit, prevrlfit):\n",
    "    \"\"\" Detects lane lines on given image using pre-existing\n",
    "    line fits from the previous video frame. It returns a\n",
    "    tuple of polynomial fits for left lane and right lane respectively.\n",
    "    \"\"\"\n",
    "    nz = warpedImage.nonzero()\n",
    "    nzy = np.array(nz[0])\n",
    "    nzx = np.array(nz[1])\n",
    "    margin = 100\n",
    "    ll_pixels = ((nzx > (prevllfit[0] * (nzy ** 2) + prevllfit[1] * nzy + prevllfit[2] - margin)) & \\\n",
    "                      (nzx < (prevllfit[0] * (nzy ** 2) + prevllfit[1] * nzy + prevllfit[2] + margin))) \n",
    "    rl_pixels = ((nzx > (prevrlfit[0] * (nzy ** 2) + prevrlfit[1] * nzy + prevrlfit[2] - margin)) & \\\n",
    "                       (nzx < (prevrlfit[0] * (nzy ** 2) + prevrlfit[1] * nzy + prevrlfit[2] + margin)))\n",
    "\n",
    "    llx = nzx[ll_pixels]\n",
    "    lly = nzy[ll_pixels] \n",
    "    rlx = nzx[rl_pixels]\n",
    "    rly = nzy[rl_pixels]\n",
    "    \n",
    "    llfit = np.polyfit(lly, llx, 2)\n",
    "    rlfit = np.polyfit(rly, rlx, 2)\n",
    "    \n",
    "    ll_c2_error = (llfit[0] - prevllfit[0]) / prevllfit[0]\n",
    "    ll_c1_error = (llfit[1] - prevllfit[1]) / prevllfit[1]\n",
    "    ll_c_error = (llfit[2] - prevllfit[2]) / prevllfit[2]\n",
    "    \n",
    "    rl_c2_error = (rlfit[0] - prevrlfit[0]) / prevrlfit[0]\n",
    "    rl_c1_error = (rlfit[1] - prevrlfit[1]) / prevrlfit[1]\n",
    "    rl_c_error = (rlfit[2] - prevrlfit[2]) / prevrlfit[2]\n",
    "    \n",
    "    CUTOFF = 20\n",
    "    if abs(ll_c2_error) > CUTOFF or abs(ll_c1_error) > CUTOFF or abs(rl_c2_error) > CUTOFF or abs(rl_c1_error) > CUTOFF:\n",
    "        #print(\"*** returning prev\")\n",
    "        return prevllfit, prevrlfit\n",
    "    \n",
    "    #ol = \"{}, {}, {}, {}, {}, {}\\n\".format(ll_c2_error, ll_c1_error, ll_c_error, rl_c2_error, rl_c1_error, rl_c_error)\n",
    "    #with open(\"errors.txt\", \"a\") as of:\n",
    "    #    of.write(ol)\n",
    "    \n",
    "    return llfit, rlfit\n",
    "\n",
    "\n",
    "def getImageWithLane(warpedImg, undistImg, invPerspectiveTransMatrix, llfit, rlfit, llRocM, rlRocM, vPosM):\n",
    "    ploty, leftfitx, rightfitx = getFittedLanePixels(warpedImg.shape, llfit, rlfit)\n",
    "    # Create an image to draw the lines on\n",
    "    zeroImg = np.zeros_like(warpedImg).astype(np.uint8)\n",
    "    multiChanImg = np.dstack((zeroImg, zeroImg, zeroImg))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([leftfitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rightfitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(multiChanImg, np.int_([pts]), (0, 255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix\n",
    "    newWarpedImg = cv2.warpPerspective(multiChanImg, invPerspectiveTransMatrix, (warpedImg.shape[1], warpedImg.shape[0])) \n",
    "    # Combine the result with the original undistorted image\n",
    "    result = cv2.addWeighted(undistImg, 1, newWarpedImg, 0.3, 0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    llRocM = round(llRocM, 2)\n",
    "    rlRocM = round(rlRocM, 2)\n",
    "    vPosM = round(vPosM, 2)\n",
    "    cv2.putText(result, \"(LeftRoC, RightRoC, CarOffset) = ({}m, {}m, {}m)\".format(llRocM, rlRocM, vPosM),\\\n",
    "                (int(result.shape[1] * 0.2), int(result.shape[0] * 0.05)),\\\n",
    "                font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    return result\n",
    "\n",
    "print(\"*** Lane Detection Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overall Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img, distCoeffs, camMtx, perspTransMtx, invPerspTransMtx, prevllfit=None, prevrlfit=None):\n",
    "    dimg = getUndistortedImage(img, camMtx, distCoeffs)\n",
    "    colthreshimg_s = colorThresholding(dimg, channel=2, thresh=(180,255))\n",
    "    absthreshimg = gradientAbsoluteThresholding(dimg, ksize=5, thresh=(20,80))\n",
    "    #\n",
    "    #Direction of gradient == +/- np.pi/2 is a vertical line.\n",
    "    #We'll never have a fully vertical line at this point due to perspective.\n",
    "    #So use something smaller than np.pi/2 as max\n",
    "    #graddirthreshimg = gradientDirectionThresholding(dimg, ksize=13, thresh=(0.7,1.3))\n",
    "    #gradmagthreshimg = gradientMagnitudeThresholding(dimg, ksize=5, thresh=(30,100))\n",
    "    #\n",
    "    combinedimg = np.zeros_like(colthreshimg_s)\n",
    "    combinedimg[((colthreshimg_s == 1) | (absthreshimg == 1))] = 1\n",
    "    #\n",
    "    #images = [dimg, colthreshimg_s, absthreshimg, gradmagthreshimg, graddirthreshimg, combinedimg]\n",
    "    #labels = [\"Undistorted\", \"S-Channel Color\", \"Gradient AbsoluteX\", \"Gradient Magnitude\", \"Gradient Direction\", \"Combined\"]\n",
    "    #plotMultipleImages(images, labels, tfile, \"gray\")\n",
    "    #\n",
    "    warpedCombinedImage = getPerspectiveTransformedImage(combinedimg, perspTransMtx)\n",
    "    if prevllfit is None or prevrlfit is None:\n",
    "        llfit, rlfit = slidingWindowLaneDetect(warpedCombinedImage)\n",
    "    else:\n",
    "        llfit, rlfit = targetedLaneDetect(warpedCombinedImage, prevllfit, prevrlfit)\n",
    "    #plotLaneFit(timg, llfit, rlfit)\n",
    "    img_shape = warpedCombinedImage.shape\n",
    "    #llRadCurvePixels, rlRadCurvePixels = getRadiusOfCurvatureOfFitInPixels(img_shape, llfit, rlfit)\n",
    "    llRadCurveMeters, rlRadCurveMeters = getRadiusOfCurvatureOfFitInMeters(img_shape, llfit, rlfit)\n",
    "    #\n",
    "    vehicleDeviationFromLaneCenterInMeters = getVehicleDeviationFromLaneCenterInMeters(img_shape, llfit, rlfit)\n",
    "    #\n",
    "    imgWithLane = getImageWithLane(warpedCombinedImage, dimg, invPerspTransMtx,\\\n",
    "                                   llfit, rlfit, llRadCurveMeters, rlRadCurveMeters,\\\n",
    "                                   vehicleDeviationFromLaneCenterInMeters)\n",
    "    #plotImage(imgWithLane)\n",
    "    return imgWithLane, llfit, rlfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testPipelineOnTestImages():\n",
    "    ret, camMtx, distCoeffs, rvecs, tvecs = calibrateCamera()\n",
    "    perspTransMtx = getPerspectiveTransformationMatrix()\n",
    "    invPerspTransMtx = getPerspectiveTransformationMatrix(inverse=True)\n",
    "    tfiles = glob.glob('test_images/test*.jpg')\n",
    "    for tfile in tfiles:\n",
    "        timg = mpimg.imread(tfile)\n",
    "        imgWithLane, llfit, rlfit = pipeline(timg, distCoeffs, camMtx,\\\n",
    "                                             perspTransMtx, invPerspTransMtx)\n",
    "        #plotImage(imgWithLane)\n",
    "        plt.figure(figsize=(10, 12))\n",
    "        plt.imshow(imgWithLane)\n",
    "\n",
    "#testPipelineOnTestImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lane Detection on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "ret, camMtx, distCoeffs, rvecs, tvecs = calibrateCamera()\n",
    "perspTransMtx = getPerspectiveTransformationMatrix()\n",
    "invPerspTransMtx = getPerspectiveTransformationMatrix(inverse=True)\n",
    "prevllfit = None\n",
    "prevrlfit = None\n",
    "def process_image(image):\n",
    "    global prevllfit\n",
    "    global prevrlfit\n",
    "    laneDetectionFunction = targetedLaneDetect\n",
    "    imgWithLane, prevllfit, prevrlfit = pipeline(image, distCoeffs,\\\n",
    "                                                 camMtx, perspTransMtx,\\\n",
    "                                                 invPerspTransMtx, prevllfit, prevrlfit)\n",
    "    return imgWithLane\n",
    "\n",
    "outvideofile = 'project_video_ld.mp4'\n",
    "pvideo = VideoFileClip(\"project_video.mp4\")\n",
    "ovideo = pvideo.fl_image(process_image)\n",
    "%time ovideo.write_videofile(outvideofile, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(outvideofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
